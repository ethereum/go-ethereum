// Copyright 2025 The go-ethereum Authors
// This file is part of the go-ethereum library.
//
// The go-ethereum library is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// The go-ethereum library is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with the go-ethereum library. If not, see <http://www.gnu.org/licenses/>.

package filtermaps

import (
	"errors"
	"fmt"
	"math"
	"sort"
	"time"

	"github.com/ethereum/go-ethereum/common"
	"github.com/ethereum/go-ethereum/common/lru"
	"github.com/ethereum/go-ethereum/core/rawdb"
	"github.com/ethereum/go-ethereum/ethdb"
	"github.com/ethereum/go-ethereum/log"
)

const (
	databaseVersion   = 4    // reindexed if database version does not match
	cachedLastBlocks  = 1000 // last block of map pointers
	cachedLvPointers  = 1000 // first log value pointer of block pointers
	maxWritesPerBatch = 1000000
)

// mapDatabase implements the database storage layer for filter maps and the
// belonging pointers.
type mapDatabase struct {
	params     *Params
	db         ethdb.KeyValueStore
	hashScheme bool

	lastBlockCache *lru.Cache[uint32, lastBlockOfMap]
	lvPointerCache *lru.Cache[uint64, uint64]

	testReadRows bool
}

// lastBlockOfMap is used for storing and caching the (number, hash) pairs
// belonging to the last block of each map.
type lastBlockOfMap struct {
	number uint64
	hash   common.Hash
}

// newMapDatabase created a new mapDatabase layer.
func newMapDatabase(params *Params, db ethdb.KeyValueStore, hashScheme bool) *mapDatabase {
	return &mapDatabase{
		params:         params,
		db:             db,
		hashScheme:     hashScheme,
		lastBlockCache: lru.NewCache[uint32, lastBlockOfMap](cachedLastBlocks),
		lvPointerCache: lru.NewCache[uint64, uint64](cachedLvPointers),
	}
}

// loadMapRange loads the valid and dirty map ranges and known epoch boundaries
// from the database.
func (m *mapDatabase) loadMapRange() (valid, dirty rangeSet[uint32], knownEpochs uint32, found bool) {
	fmr, ok, err := rawdb.ReadFilterMapsRange(m.db)
	if !ok || err != nil || fmr.Version != databaseVersion {
		return
	}
	return decodeRangeSet32(fmr.ValidMaps), decodeRangeSet32(fmr.DirtyMaps), fmr.KnownEpochs, true
}

// storeMapRange stores the valid and dirty map ranges and known epoch boundaries
// into the database.
func (m *mapDatabase) storeMapRange(valid, dirty rangeSet[uint32], knownEpochs uint32) {
	rawdb.WriteFilterMapsRange(m.db, rawdb.FilterMapsRange{
		Version:     databaseVersion,
		ValidMaps:   encodeRangeSet32(valid),
		DirtyMaps:   encodeRangeSet32(dirty),
		KnownEpochs: knownEpochs,
	})
}

// deleteMapRange removes the map range entry from the database, signaling a
// revert to the non-initialized state.
func (m *mapDatabase) deleteMapRange() {
	rawdb.DeleteFilterMapsRange(m.db)
}

func decodeRangeSet32(enc []uint32) rangeSet[uint32] {
	rs := make(rangeSet[uint32], len(enc)/2)
	for i := range rs {
		rs[i] = common.NewRange(enc[i*2], enc[i*2+1])
	}
	return rs
}

func encodeRangeSet32(rs rangeSet[uint32]) []uint32 {
	enc := make([]uint32, len(rs)*2)
	for i, r := range rs {
		enc[i*2] = r.First()
		enc[i*2+1] = r.Count()
	}
	return enc
}

// getBlockLvPointer returns the starting log value index where the log values
// generated by the given block are located.
func (m *mapDatabase) getBlockLvPointer(blockNumber uint64) (uint64, error) {
	if lvPointer, ok := m.lvPointerCache.Get(blockNumber); ok {
		return lvPointer, nil
	}
	lvPointer, err := rawdb.ReadBlockLvPointer(m.db, blockNumber)
	if err != nil {
		return 0, fmt.Errorf("failed to retrieve log value pointer of block %d: %v", blockNumber, err)
	}
	m.lvPointerCache.Add(blockNumber, lvPointer)
	return lvPointer, nil
}

// storeBlockLvPointer stores the starting log value index where the log values
// generated by the given block are located.
func (m *mapDatabase) storeBlockLvPointer(db ethdb.KeyValueWriter, blockNumber, lvPointer uint64) {
	m.lvPointerCache.Add(blockNumber, lvPointer)
	rawdb.WriteBlockLvPointer(db, blockNumber, lvPointer)
}

// getLastBlockOfMap returns the number and hash of the block that generated the
// last log value entry of the given map.
func (m *mapDatabase) getLastBlockOfMap(mapIndex uint32) (uint64, common.Hash, error) {
	if lastBlock, ok := m.lastBlockCache.Get(mapIndex); ok {
		return lastBlock.number, lastBlock.hash, nil
	}
	number, hash, err := rawdb.ReadFilterMapLastBlock(m.db, mapIndex)
	if err != nil {
		return 0, common.Hash{}, fmt.Errorf("failed to retrieve last block of map %d: %v", mapIndex, err)
	}
	m.lastBlockCache.Add(mapIndex, lastBlockOfMap{number: number, hash: hash})
	return number, hash, nil
}

// storeLastBlockOfMap stores the number of the block that generated the last
// log value entry of the given map.
func (m *mapDatabase) storeLastBlockOfMap(db ethdb.KeyValueWriter, mapIndex uint32, number uint64, hash common.Hash) {
	m.lastBlockCache.Add(mapIndex, lastBlockOfMap{number: number, hash: hash})
	rawdb.WriteFilterMapLastBlock(db, mapIndex, number, hash)
}

// deleteEpochRows deletes the map rows from an entire epoch.
func (m *mapDatabase) deleteEpochRows(epoch uint32, stopCallback func() bool) (bool, error) {
	deleteFn := func(db ethdb.KeyValueStore, hashScheme bool, stopCb func(bool) bool) error {
		first := m.params.mapRowIndex(m.params.firstEpochMap(epoch), 0)
		afterLast := m.params.mapRowIndex(m.params.firstEpochMap(epoch+1), 0)
		return rawdb.DeleteFilterMapRows(db, common.NewRange(first, afterLast-first), hashScheme, stopCb)
	}
	action := fmt.Sprintf("Deleting epoch #%d", epoch)
	switch err := m.safeDeleteWithLogs(deleteFn, action, stopCallback); err {
	case nil:
		return true, nil
	case rawdb.ErrDeleteRangeInterrupted:
		return false, nil
	default:
		return false, err
	}
}

// reset deletes the entire log index database. Note that deleteMapRange should
// be used first in order to prevent trying to use a partially deleted database
// later.
func (m *mapDatabase) reset(stopCallback func() bool) (bool, error) {
	rawdb.DeleteFilterMapsRange(m.db)
	if err := m.safeDeleteWithLogs(rawdb.DeleteFilterMapsDb, "Resetting log index database", stopCallback); err != rawdb.ErrDeleteRangeInterrupted {
		return err == nil, err
	}
	return false, nil
}

// deletePointers removes the last block of map and block log value pointers
// belonging to the specified map range.
// Note that in order to determine the relevant block range, the last block
// pointer of the map before the specified map range has to be present unless
// the range starts at map 0. The last block pointer of the last map in the range
// also has to be present unless the range ends at MaxUint32-1.
func (m *mapDatabase) deletePointers(deleteMaps common.Range[uint32], stopCallback func() bool) error {
	var firstBlock, afterLastBlock uint64
	if deleteMaps.First() > 0 {
		lb, _, err := m.getLastBlockOfMap(deleteMaps.First() - 1)
		if err != nil {
			return err
		}
		firstBlock = lb + 1
	}
	if deleteMaps.AfterLast() < math.MaxUint32 {
		lb, _, err := m.getLastBlockOfMap(deleteMaps.Last())
		if err != nil {
			return err
		}
		afterLastBlock = lb
	} else {
		afterLastBlock = math.MaxUint64
	}
	if afterLastBlock > firstBlock {
		m.lvPointerCache.Purge()
		blockRange := common.NewRange[uint64](firstBlock, afterLastBlock-firstBlock) // keep last pointer
		if err := rawdb.DeleteBlockLvPointers(m.db, blockRange, m.hashScheme, func(bool) bool { return stopCallback() }); err != nil {
			return err
		}
	}
	if deleteMaps.Count() > 1 {
		m.lastBlockCache.Purge()
		mapRange := common.NewRange[uint32](deleteMaps.First(), deleteMaps.Count()-1) // keep last pointer
		if err := rawdb.DeleteFilterMapLastBlocks(m.db, mapRange, m.hashScheme, func(bool) bool { return stopCallback() }); err != nil {
			return err
		}
	}
	return nil
}

// writePointers writes the pointers belonging to the give maps to the database.
func (m *mapDatabase) writePointers(writeRange common.Range[uint32], maps []*finishedMap, stopCallback func() bool) (bool, error) {
	batch := m.db.NewBatch()
	var (
		batchCnt uint32
		writeErr error
	)
	checkStopOrCommit := func() bool {
		batchCnt++
		if batchCnt >= maxWritesPerBatch {
			if writeErr = batch.Write(); writeErr != nil {
				return true
			}
			if stopCallback() {
				return true
			}
			batch = m.db.NewBatch()
			batchCnt = 0
		}
		return false
	}
	for mapIndex := range writeRange.Iter() {
		fm := maps[mapIndex-writeRange.First()]
		m.storeLastBlockOfMap(batch, mapIndex, fm.lastBlock.number, fm.lastBlock.hash)
		if checkStopOrCommit() {
			return false, writeErr
		}
		for i, lvPtr := range fm.blockPtrs {
			m.storeBlockLvPointer(batch, fm.firstBlock()+uint64(i), lvPtr)
			if checkStopOrCommit() {
				return false, writeErr
			}
		}
	}
	if err := batch.Write(); err != nil {
		return false, err
	}
	return true, nil
}

// getFilterMapRows returns a batch of filter maps rows from the same row index,
// each truncated to the length limit of the specified mapping layer.
// The function assumes that the map indices are in strictly ascending order.
// Note that the function modifies the mapIndices slice.
func (m *mapDatabase) getFilterMapRows(mapIndices []uint32, rowIndex, layerIndex uint32) ([]FilterRow, error) {
	rows := make([]FilterRow, len(mapIndices))
	readRows := make([]*FilterRow, len(mapIndices))
	for i := range rows {
		readRows[i] = &rows[i]
	}
	for dbLayer := range min(layerIndex+1, uint32(len(m.params.rowGroupSize))) {
		if err := m.getFilterMapRowsOfDbLayer(mapIndices, rowIndex, dbLayer, readRows); err != nil {
			return nil, err
		}
		j := 0
		maxRowLength := m.params.maxRowLength[dbLayer]
		for i, row := range readRows {
			if uint32(len(*row)) == maxRowLength {
				if j != i {
					mapIndices[j] = mapIndices[i]
					readRows[j] = readRows[i]
				}
				j++
			}
		}
		if j == 0 {
			break
		}
		mapIndices = mapIndices[:j]
		readRows = readRows[:j]
	}
	return rows, nil
}

// getFilterMapRowsOfDbLayer loads the part of the given filter rows belonging to
// the specified database layer and appends it to a slice of already existing
// rows. If dbLayer > 0 then it is assumed that the data from all previous database
// layers have been appended to the filter rows.
func (m *mapDatabase) getFilterMapRowsOfDbLayer(mapIndices []uint32, rowIndex, dbLayer uint32, appendTo []*FilterRow) error {
	var ptr int
	for ptr < len(mapIndices) {
		var (
			groupIndex  = m.params.mapGroupIndex(mapIndices[ptr], dbLayer)
			groupLength = 1
		)
		for ptr+groupLength < len(mapIndices) && m.params.mapGroupIndex(mapIndices[ptr+groupLength], dbLayer) == groupIndex {
			groupLength++
		}
		if err := m.getFilterMapRowsOfDbLayerGroup(mapIndices[ptr:ptr+groupLength], rowIndex, dbLayer, appendTo[ptr:ptr+groupLength]); err != nil {
			return err
		}
		ptr += groupLength
	}
	return nil
}

// getFilterMapRowsOfDbLayerGroup loads the part of the given filter rows belonging to
// the specified database layer and appends it to a slice of already existing
// rows. The map indices should be located in the same row group according to the
// group size at the given database layer.
func (m *mapDatabase) getFilterMapRowsOfDbLayerGroup(mapIndices []uint32, rowIndex, dbLayer uint32, appendTo []*FilterRow) error {
	var (
		groupSize   = m.params.rowGroupSize[dbLayer]
		groupIndex  = m.params.mapGroupIndex(mapIndices[0], dbLayer)
		mapRowIndex = m.params.mapRowIndex(groupIndex, rowIndex)
	)
	if groupSize == 1 {
		row, err := rawdb.ReadFilterMapSingleRow(m.db, mapRowIndex, dbLayer, m.params.logMapWidth)
		if err != nil {
			return fmt.Errorf("failed to retrieve row %d of row %d layer %d: %v", groupIndex, rowIndex, dbLayer, err)
		}
		*appendTo[0] = append(*appendTo[0], FilterRow(row)...)
		return nil
	}
	rows, err := rawdb.ReadFilterMapRowGroup(m.db, mapRowIndex, dbLayer, groupSize, m.params.logMapWidth)
	if err != nil {
		return fmt.Errorf("failed to retrieve row group %d of row %d layer %d: %v", groupIndex, rowIndex, dbLayer, err)
	}
	for i, mapIndex := range mapIndices {
		if m.params.mapGroupIndex(mapIndex, dbLayer) != groupIndex {
			return fmt.Errorf("maps are not in the same base row group, index: %d, group: %d", mapIndex, groupIndex)
		}
		*appendTo[i] = append(*appendTo[i], FilterRow(rows[m.params.mapGroupOffset(mapIndex, dbLayer)])...)
	}
	return nil
}

// getFilterMap returns the filter map at the specified index.
func (m *mapDatabase) getFilterMap(mapIndex uint32) (*finishedMap, error) {
	fm := new(finishedMap)
	lastBlock, lbHash, err := m.getLastBlockOfMap(mapIndex)
	if err != nil {
		return nil, fmt.Errorf("failed to retrieve last block of map %d: %v", mapIndex, err)
	}
	fm.lastBlock = lastBlockOfMap{number: lastBlock, hash: lbHash}
	var firstBlock uint64
	if mapIndex > 0 {
		plb, _, err := m.getLastBlockOfMap(mapIndex - 1)
		if err != nil {
			return nil, fmt.Errorf("failed to retrieve last block of map %d: %v", mapIndex-1, err)
		}
		firstBlock = plb + 1
	}
	fm.blockPtrs = make([]uint64, lastBlock+1-firstBlock)
	for i := range fm.blockPtrs {
		blockPtr, err := m.getBlockLvPointer(firstBlock + uint64(i))
		if err != nil {
			return nil, fmt.Errorf("failed to retrieve block pointer %d: %v", firstBlock+uint64(i), err)
		}
		fm.blockPtrs[i] = blockPtr
	}
	for rowIndex := range m.params.mapHeight {
		var mi [1]uint32
		mi[0] = mapIndex
		row, err := m.getFilterMapRows(mi[:], rowIndex, uint32(len(m.params.rowGroupSize)-1))
		if err != nil {
			return nil, fmt.Errorf("failed to retrieve row %d of map %d: %v", rowIndex, mapIndex, err)
		}
		fm.rowData = append(fm.rowData, row[0]...)
		fm.rowPtrs = append(fm.rowPtrs, uint16(len(fm.rowData)))
	}
	return fm, nil
}

// writeMapRows updates a section of the filter map range, writing a continuous
// range of new map data and/or removing dirty data. writeRange and deleteRange
// can and should overlap if dirty data is being overwritten with new map data.
// writeRange alone should only be specified where the database is known to be
// empty.
// keepEmptyRange is optional, it signals that a certain range is known to be
// empty in the database and should also stay so. It should not overlap with the
// other two ranges. If these three ranges together cover an entire row group
// then the entire group can be updated without reading its previous value,
// thereby speeding up the write process significantly.
// Note that writeMapRows only updates the filter map rows and does not touch
// the belonging pointers.
func (m *mapDatabase) writeMapRows(writeRange, deleteRange, keepEmptyRange common.Range[uint32], maps []*finishedMap, stopCallback func() bool) (bool, error) {
	if !writeRange.Intersection(keepEmptyRange).IsEmpty() || !deleteRange.Intersection(keepEmptyRange).IsEmpty() {
		panic("invalid writeMapRows map ranges")
	}
	writePattern := m.makeWritePattern(writeRange, deleteRange, keepEmptyRange)
	batch := m.db.NewBatch()
	rowsPerBatch := uint32(max(maxWritesPerBatch/len(writePattern), 1))
	var (
		batchCnt uint32
		writeErr error
	)
	checkStopOrCommit := func() bool {
		batchCnt++
		if batchCnt >= rowsPerBatch {
			if writeErr = batch.Write(); writeErr != nil {
				return true
			}
			if stopCallback() {
				return true
			}
			batch = m.db.NewBatch()
			batchCnt = 0
		}
		return false
	}

	for rowIndex := range m.params.mapHeight {
		if err := m.writeRowUpdates(batch, writePattern, writeRange, maps, rowIndex); err != nil {
			return false, err
		}
		if checkStopOrCommit() {
			return false, writeErr
		}
	}
	if err := batch.Write(); err != nil {
		return false, err
	}
	return true, nil
}

type writePatterItem struct {
	mapIndex, dbLayer                       uint32
	writeRange, deleteRange, keepEmptyRange common.Range[uint32]
}

// makeWritePattern pre-generates the order of operations that need to be repeated
// for every row.
func (m *mapDatabase) makeWritePattern(writeRange, deleteRange, keepEmptyRange common.Range[uint32]) (writePattern []writePatterItem) {
	for dbLayer, groupSize := range m.params.rowGroupSize {
		updateRange := deleteRange.Union(writeRange)
		firstGroup, lastGroup := updateRange.First()/groupSize, updateRange.Last()/groupSize
		for i := firstGroup; i <= lastGroup; i++ {
			groupRange := common.NewRange[uint32](i*groupSize, groupSize)
			writePattern = append(writePattern, writePatterItem{
				mapIndex:       i * groupSize,
				dbLayer:        uint32(dbLayer),
				writeRange:     writeRange.Intersection(groupRange),
				deleteRange:    deleteRange.Intersection(groupRange),
				keepEmptyRange: keepEmptyRange.Intersection(groupRange),
			})
		}
	}
	sort.Slice(writePattern, func(i, j int) bool {
		return writePattern[i].mapIndex < writePattern[j].mapIndex ||
			(writePattern[i].mapIndex == writePattern[j].mapIndex && writePattern[i].dbLayer < writePattern[j].dbLayer)
	})
	return
}

// writeRowUpdates performs the filter row update operation on a single row.
func (m *mapDatabase) writeRowUpdates(batch ethdb.Batch, writePattern []writePatterItem, writeRange common.Range[uint32], maps []*finishedMap, rowIndex uint32) error {
	for _, w := range writePattern {
		if groupSize := m.params.rowGroupSize[w.dbLayer]; groupSize == 1 {
			var row FilterRow
			if writeRange.Includes(w.mapIndex) {
				row = maps[w.mapIndex-writeRange.First()].getRow(rowIndex, m.params.maxRowLength[w.dbLayer])
			}
			var from uint32
			if w.dbLayer > 0 {
				from = m.params.maxRowLength[w.dbLayer-1]
			}
			if uint32(len(row)) > from {
				row = row[from:]
			} else {
				row = nil
			}
			if len(row) > 0 || !w.deleteRange.IsEmpty() {
				rawdb.WriteFilterMapSingleRow(batch, m.params.mapRowIndex(w.mapIndex, rowIndex), w.dbLayer, row, m.params.logMapWidth)
			}
		} else {
			rows := make([][]uint32, groupSize)
			writeGroup := !w.deleteRange.IsEmpty()
			if w.writeRange.Count()+w.deleteRange.Count()-w.writeRange.Intersection(w.deleteRange).Count()+w.keepEmptyRange.Count() < groupSize {
				oldRows, err := rawdb.ReadFilterMapRowGroup(m.db, m.params.mapRowIndex(w.mapIndex, rowIndex), w.dbLayer, groupSize, m.params.logMapWidth)
				m.testReadRows = true
				if err != nil {
					return err
				}
				for i := range groupSize {
					if mapIndex := w.mapIndex + i; !w.writeRange.Includes(mapIndex) && !w.deleteRange.Includes(mapIndex) && !w.keepEmptyRange.Includes(mapIndex) {
						rows[i] = oldRows[i]
					}
				}
			}
			var from uint32
			if w.dbLayer > 0 {
				from = m.params.maxRowLength[w.dbLayer-1]
			}
			to := m.params.maxRowLength[w.dbLayer]
			for i := range groupSize {
				if writeRange.Includes(w.mapIndex + i) {
					if row := maps[w.mapIndex+i-writeRange.First()].getRow(rowIndex, to); uint32(len(row)) > from {
						rows[i] = row[from:]
						writeGroup = true
					}
				}
			}
			if writeGroup {
				rawdb.WriteFilterMapRowGroup(batch, m.params.mapRowIndex(w.mapIndex, rowIndex), w.dbLayer, rows, m.params.logMapWidth)
			}
		}
	}
	return nil
}

// safeDeleteWithLogs is a wrapper for a function that performs a safe range
// delete operation using rawdb.SafeDeleteRange. It emits log messages if the
// process takes long enough to call the stop callback.
func (m *mapDatabase) safeDeleteWithLogs(deleteFn func(db ethdb.KeyValueStore, hashScheme bool, stopCb func(bool) bool) error, action string, stopCb func() bool) error {
	var (
		start          = time.Now()
		logPrinted     bool
		lastLogPrinted = start
	)
	switch err := deleteFn(m.db, m.hashScheme, func(deleted bool) bool {
		if deleted && !logPrinted || time.Since(lastLogPrinted) > time.Second*10 {
			log.Info(action+" in progress...", "elapsed", common.PrettyDuration(time.Since(start)))
			logPrinted, lastLogPrinted = true, time.Now()
		}
		return stopCb()
	}); {
	case err == nil:
		if logPrinted {
			log.Info(action+" finished", "elapsed", common.PrettyDuration(time.Since(start)))
		}
		return nil
	case errors.Is(err, rawdb.ErrDeleteRangeInterrupted):
		log.Warn(action+" interrupted", "elapsed", common.PrettyDuration(time.Since(start)))
		return err
	default:
		log.Error(action+" failed", "error", err)
		return err
	}
}

// removeBloomBits removes old bloom bits data from the database.
func (m *mapDatabase) removeBloomBits(stopCb func() bool) {
	m.safeDeleteWithLogs(rawdb.DeleteBloomBitsDb, "Removing old bloom bits database", stopCb)
}

// storeEpochCheckpoint writes a single checkpoint (known epoch boundary) to the
// database.
func (m *mapDatabase) storeEpochCheckpoint(epoch uint32, cp epochCheckpoint) {
	m.storeLastBlockOfMap(m.db, m.params.lastEpochMap(epoch), cp.BlockNumber, cp.BlockHash)
	m.storeBlockLvPointer(m.db, cp.BlockNumber, cp.FirstIndex)
}

// storeCheckpointList writes a list of checkpoints to the database.
func (m *mapDatabase) storeCheckpointList(firstEpoch uint32, cpList checkpointList) {
	for i, cp := range cpList {
		m.storeEpochCheckpoint(firstEpoch+uint32(i), cp)
	}
}
